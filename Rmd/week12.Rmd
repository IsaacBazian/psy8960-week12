---
title: "PSY 8960 Week 12"
author: "Isaac Bazian"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


## Script Settings and Resources
```{r script_settings_and_resources, message = FALSE}
#setwd(dirname(rstudioapi::getActiveDocumentContext()$path)) comment for now, probably won't need
library(tidyverse)
library(RedditExtractoR) #More testing, trying a specialty package
library(tm)
library(qdap)
library(textstem)
library(RWeka)
library(ldatuning)
library(topicmodels)
library(parallel)
library(doParallel)
library(tidytext)
library(wordcloud)
```

## Data Import and Cleaning

```{r data_import}
# riopsychology_urls <- find_thread_urls(keywords = NA, sort_by = "new", subreddit = "IOPsychology", period = "year")
# 
# riopsychology_content <- get_thread_content(riopsychology_urls$url)
# 
# title <- riopsychology_content$threads$title
# upvotes <- riopsychology_content$threads$upvotes
# 
# week12_data <- tibble(title, upvotes)
# 
# write_csv(week12_data, "../data/week12_data.csv")


week12_tbl <- read_csv("../data/week12_data.csv")


```




```{r preprocess}
week12_tbl_pre_preprocess <- week12_tbl %>% 
  mutate(across("title", str_replace_all, "-|/", " ")) #This is done because otherwise words connected by a hyphen or slash end up as one word with removePunctuation

io_corpus_original <- VCorpus(VectorSource(week12_tbl_pre_preprocess$title))
io_corpus <- io_corpus_original %>% 
  tm_map(content_transformer(replace_abbreviation)) %>% 
  tm_map(content_transformer(replace_contraction)) %>% 
  tm_map(content_transformer(replace_symbol)) %>% #Dollar symbol came up
  tm_map(content_transformer(str_to_lower)) %>% 
  tm_map(content_transformer(replace_number)) %>%
  tm_map(removePunctuation) %>% 
  tm_map(removeWords, c(stopwords("en"), "io", "i o", "io psychology", "i o psychology", "io psych", "i o psych", "riopsychology", "iopsychology", "psychologist", "psychologists")) %>% 
  tm_map(stripWhitespace) %>% 
  tm_map(content_transformer(lemmatize_words))

  #tm_filter(io_corpus, FUN = function(x) { return(nchar(stripWhitespace(x$content)[[1]]) > 0) }) #RL code to filter empty rows
```


```{r compare_them}
compare_them <- function(corp1, corp2) {
  rows <- 1:length(corp1)
  pick <- sample(rows, 1)
  corp_list <- list("Original" = content(corp1[[pick]]), "Preprocessed" = content(corp2[[pick]]))
  return(corp_list)
}

compare_them(io_corpus_original, io_corpus)
```
## Analysis

SPARSENESS SLIMMING WILL NEED TO CHANGE WITH NEW DATA
```{r bigram_dtm}
myTokenizer <- function(x) { 
  NGramTokenizer(x, Weka_control(min=1, max=2)) 
  }
io_dtm <- DocumentTermMatrix(io_corpus, control = list(tokenize = myTokenizer))
io_slim_dtm <- removeSparseTerms(io_dtm, .996)

io_dtm #REMOVE LATER, CODING CHECK
io_slim_dtm

io_dtm_tbl <- as_tibble(as.matrix(io_dtm)) %>% #TEMP TO TROUBLESHOOT
  mutate(sums = rowSums(io_dtm_tbl)) %>% 
  mutate(zero = (sums == 0)) %>% 
  select(sums, zero) #487, 570, 737, 

```

Maybe put this in Visualization?
```{r lda_tuning}
local_cluster <- makeCluster(7)
registerDoParallel(local_cluster)

lda_tuning <- FindTopicsNumber(
  io_dtm,
  topics = seq(2, 20, 1),
  metrics = c("Griffiths2004",
              "CaoJuan2009",
              "Arun2010",
              "Deveaud2014"),
  verbose = T
  )

FindTopicsNumber_plot(lda_tuning)


stopCluster(local_cluster)
registerDoSEQ()
```

```{r lda_results}
lda_results <- LDA(io_dtm, 5)

lda_betas <- tidy(lda_results, matrix="beta")

# lda_betas %>%
# group_by(topic) %>%
# top_n(10, beta) %>%
# arrange(topic, -beta) %>%
# View


lda_gammas <- tidy(lda_results, matrix="gamma")

gamma_vals <- lda_gammas %>%
group_by(document) %>%
top_n(1, gamma) %>%
slice(1) %>%
ungroup %>%
mutate(document = as.numeric(document)) %>%
arrange(document)


topics_tbl <- tibble(doc_id = 1:length(io_corpus),
                     original = week12_tbl$title,
                     topic = gamma_vals$topic,
                     probability = gamma_vals$gamma)

```


```{r upvotes_by_topic}

final_tbl <- topics_tbl %>% 
  mutate(upvotes = week12_tbl$upvotes,
         topic = as.factor(topic))

TukeyHSD(aov(upvotes ~ topic, data = final_tbl))

```


## Visualization

```{r wordcloud}
wordcloud_tbl <- as_tibble(as.matrix(io_dtm))

wordcloud(names(wordcloud_tbl), colSums(wordcloud_tbl), max.words = 20, colors = brewer.pal(10, "Oranges"))
```


